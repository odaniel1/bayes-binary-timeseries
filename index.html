<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Bayesian methods for binary timeseries</title>

<link href="site_libs/tint-css-2015.12.29/tint.css" rel="stylesheet" />
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








</head>

<body>




<h1 class="title toc-ignore">Bayesian methods for binary timeseries</h1>



<style>
.math {
  font-size: 12pt;
}
</style>
<p><label for="tufte-mn-1" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-1" class="margin-toggle"><span class="marginnote">Binary data often also arises through a process of simplifying analysis: eg. replacing a question which could be on a continuous scale, with a cut-off: for instance, analysis of exam pass/fail rates is a simpler problem to explore than the full distribution of exam marks</span></p>
<p>Binary data occurs in many natural settings where we wish to understand the relative likelihood of one of two outcomes occuring (often referred to as failure <span class="math inline">\(0\)</span> and success). For instance whether or not a newborn child is a boy or a girl (in this context, one might be cautioned against the failure/success terminology).</p>
<p>The natural statistic of interest for binary questions is the underlying proportion of successes. Given a sample of <span class="math inline">\(n\)</span> observations with <span class="math inline">\(0 \leq s \leq n\)</span> successes, the classical (maximum likelihood) estimate for the success rate is simply <span class="math inline">\(s/n\)</span>, the proportion of the observed data that were successes.</p>
<p><label for="tufte-mn-2" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-2" class="margin-toggle"><span class="marginnote"><a href="http://varianceexplained.org/r/empirical-bayes-book/">Robinson’s</a> introduction to Empirical Bayes through baseball statistics is an excellent resource for learning the basics of binary inference. Unfortunately it does not explore timeseries.</span> In many instances it is likely that this binary data makes up a timeseries: for example in baseball, the proportion of hits a player makes out of all balls they are thrown (apparently known as <em>At Bats</em>). In this context we would expect this proportion to vary over time - both due to game specific covariates (eg. who pitched the ball), and temporal affects (eg. improving performance with experience).</p>
<p>In such applications any underlying success rate at a given point in time is likely to be correlated with success rates within the recent past and future. Estimates for the success rate that do not take into account this correlation will therefore likely be overly susceptible to natural variance.</p>
<p>Our focus will be on exploring methods for analysing binary time series under two challenging conditions:</p>
<ul>
<li><p>Where the number of observations at each time point is low - meaning that estimates of success rates which don’t take into account nearby observtaions are likely to be too broad to provide insight.</p></li>
<li><p>Where data does not arrive at routine intervals - meaning that methods that are based on differencing/neighbouring statistics are not very easy to define.</p></li>
</ul>
<div id="the-data" class="section level1">
<h1>The Data</h1>
<p><label for="tufte-mn-3" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-3" class="margin-toggle"><span class="marginnote">Data is made available through the <a href="https://api.stackexchange.com/docs">Stack Exchange API</a>; this can be queried in R usnig the <a href="https://github.com/dgrtwo/stackr">stackr</a> package - coincidentally written by the same David Robinson referenced above.</span> For an open source data set that exhibits the features defined above, we consider the acceptance rate of answers to <a href="https://stackexchange.com/">Stack Exchange</a> questions. In particular we will look at the data of a single user <a href="https://stats.stackexchange.com/users/7224/xian">Xi’an</a> on Cross Validated (stats.stackexchange) who is at the time of writing the top ranked user for the Bayesian tag.</p>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="index_files/figure-html/unnamed-chunk-1-1.png" alt="The number of questions answered in March 2020 illustrates that the data shows both low volumes, and intermittent frequency" width="672"  /> <!--
<p class="caption marginnote">-->The number of questions answered in March 2020 illustrates that the data shows both low volumes, and intermittent frequency<!--</p>--> <!--</div>--></span>
</p>
<p>A sample of the first 6 rows of the data are shown below; for the most part we work with data that is aggregated to a daily level - we will however consider one model that looks at variation within days at the end.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
date
</th>
<th style="text-align:right;">
answered
</th>
<th style="text-align:right;">
accepted
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
2011-11-05
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
2011-11-07
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
2011-11-11
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
2011-11-13
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
2011-11-19
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
2011-11-24
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
</div>
<div id="non-bayesian-methods" class="section level1">
<h1>Non-Bayesian Methods</h1>
<div id="aggregated-binomial-proportions" class="section level2">
<h2>(Aggregated) Binomial proportions</h2>
<p>Putting aside the option of treating days as independent, likely the simplest model would be to aggregate data up to a suitable level which ensures a sufficient volume of data to be able to treat units as independent, whilst maintaing relevance/utility of the outcome.</p>
<p>For our purposes a reasonable level of aggregation may be considered to be monthly data (aggregating by year feels too coarse); at this point we derive acceptance rates and confidence intervals at the monthly level using the standard (Maximum Likelihood, and normal approximation) method.</p>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="index_files/figure-html/unnamed-chunk-4-1.png" alt="Even at a monthly level there is high variance between months and no discernable trend." width="672"  /> <!--
<p class="caption marginnote">-->Even at a monthly level there is high variance between months and no discernable trend.<!--</p>--> <!--</div>--></span>
</p>
<div id="pros" class="section level3">
<h3>Pros</h3>
<ul>
<li>The method is standard, and well explained in various resources.</li>
<li>Easy to implement.</li>
</ul>
</div>
<div id="cons" class="section level3">
<h3>Cons</h3>
<ul>
<li>The resulting confidence intervals do not instill confidence.</li>
<li>There is little indication that we can discern trends.</li>
<li>We cannot estimate acceptance rates for months which do not have any data.</li>
</ul>
</div>
</div>
<div id="loess-smoothing" class="section level2">
<h2>Loess Smoothing</h2>
</div>
<div id="binary-arima" class="section level2">
<h2>Binary ARIMA</h2>
</div>
</div>
<div id="bayesian-approaches" class="section level1">
<h1>Bayesian Approaches</h1>
<div id="hierarchical-logistic-regression" class="section level2">
<h2>Hierarchical logistic regression</h2>
</div>
<div id="propogating-priors" class="section level2">
<h2>Propogating Priors</h2>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="index_files/figure-html/unnamed-chunk-6-1.png" alt=" " width="672"  /> <!--
<p class="caption marginnote">--> <!--</p>--> <!--</div>--></span>
</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
